# PAGE 1 TITLE

### 用于临床结果预测的多类别、多组学数据集成的基准集成机器学习算法

### 一个对晚期融合方法的比较研究

  
  

# PAGE 2 RESEARCH OVERVIEW

  

- PROBLEM:用于临床结果预测的多组学数据融合

- CHALLENGE:高维数据，异构数据，样本数量小

- SOLUTION:集成机器学习中的晚期融合策略

- APPLICATION:肝细胞癌，乳腺癌，炎症性肠病

  
  

# PAGE 3 MOTIVATION

  

* **多组学数据提供互补信息** (Multi-omics data provides complementary information):这句话的意思是，来自不同“组学”层次（例如基因组学、转录组学、蛋白质组学等）的数据，可以相互补充，提供更全面的信息。这就像你从不同的角度（比如照片、视频和文字描述）去了解一个事件，能获得比单一角度更完整、更深入的理解。

  

---

  

### **优势**

  

* **更好地理解疾病机制** (Better understanding of disease mechanisms)：通过整合多种组学数据，科学家可以更全面地研究疾病的复杂过程，从而更深入地了解疾病的根本原因。

* **改进临床结果预测** (Improved clinical outcome prediction)：综合分析多种类型的数据（例如基因突变、蛋白质表达水平等），可以更准确地预测病人的治疗反应、疾病进展或预后。

  

---

  

### **多组学整合的挑战** (Challenges in multi-omics integration)

  

* **维度灾难** (Curse of dimensionality)：当将所有组学数据拼接在一起时，特征数量会变得非常庞大，这会导致模型训练困难，容易出现过拟合。

* **异构数据类型** (Heterogeneous data types)：不同的组学数据有着不同的格式、规模和统计特性，这使得将它们有效整合起来成为一项挑战。

* **缺失值和批次效应** (Missing values and batch effects)：

* **缺失值**：在实验中，某些数据点可能没有被成功测量到，这需要在数据整合前进行处理。

* **批次效应**：由于实验操作、试剂或设备等非生物学因素的差异，导致数据中出现系统性偏差，这会影响结果的准确性。

  
  

### **BENIFITS**

  

### **增强的准确性** (Enhanced accuracy)

通过结合来自多个数据源的信息，可以更全面地了解生物系统，从而**提高预测和分类的准确性**。这比仅依赖单一数据类型（比如只看基因或只看蛋白质）要好得多。

  

### **新颖生物标志物的发现** (Novel biomarker discovery)

多组学分析可以揭示在单一组学研究中无法发现的**新的生物标志物**。这些标志物可能是疾病诊断、预后或治疗反应的关键。例如，一个基因突变可能需要与某个蛋白质的表达水平结合，才能成为有效的标志物。

  

### **疾病亚型分类** (Disease subtyping)

许多疾病，尤其是癌症，并非单一疾病，而是具有不同特征和预后的多种亚型。整合多组学数据可以帮助科学家更精确地将疾病患者**划分为不同的亚群**，从而实现更精准的治疗。

  

### **治疗靶点** (Therapeutic targets)

通过识别那些与疾病亚型或特定机制相关的关键分子网络，多组学分析可以帮助研究人员**发现和验证新的治疗靶点**。这对于开发更有效、更个性化的药物至关重要。

  
  
  
  

# PAGE 5 Data Integration Strategies

在**多组学数据整合**（Multi-omics data integration）中，有三种主要的策略或方法。多组学整合的目的是将来自不同生物学层次的数据（如基因组学、转录组学、蛋白质组学等）结合起来，以更全面地理解复杂的生物系统或疾病。

  

这些方法的主要区别在于数据整合发生的**阶段**。

  

---

  

### 早整合 (Early Integration)

  

* **操作**: 将所有不同类型的组学数据直接**拼接**（concatenate）成一个巨大的数据集。

* **模型**: 在这个大数据集上训练一个单一的分类器。

* **问题**: 这种方法最大的挑战是**高维性灾难**（curse of dimensionality）。由于直接将数据拼接，特征数量会急剧增加，导致模型训练困难、过拟合风险高，并且需要大量的计算资源。

  

---

  

### 中整合 (Intermediate Integration)

  

* **操作**: 不直接拼接原始数据，而是先对每种组学数据进行**降维**或**特征提取**，将它们转换成一个共同的、更低维度的“表示”（common representation）。例如，可以提取每种组学数据的核心模式或特征向量。

* **模型**: 在这个共同表示上训练模型。

* **问题**: 这种方法的一个主要缺点是**临床解释困难**。降维后的“共同表示”往往是抽象的数学向量，难以直接映射回原始的生物学特征（如特定的基因或蛋白质），因此很难理解模型是如何做出预测的。

  

---

  

### 晚整合 (Late Integration)

  

* **操作**: 为每种组学数据单独训练一个模型。每个模型都专注于分析一种特定的数据类型。

* **模型**: 最后，将这些单独模型的预测结果（例如，每个模型给出的类别概率或分数）进行**汇总**（aggregate），得到最终的预测结果。汇总方法可以是简单的平均、加权平均，或是用另一个模型来组合这些结果。

* **优点**: 这是“这项工作的重点”。这种方法的好处在于它避免了高维性灾难，每个模型可以针对其特定的数据类型进行优化，并且结果更易于理解。

  
  

# PAGE 6 Advantages of Late Integration

**晚期整合（Late Integration）**策略的优点。

  

---

  

### **优点**

  

* **降低维度** (Reduces dimensionality)：因为为每种数据模态（如基因组学、蛋白质组学）训练了单独的模型，所以避免了将所有数据拼接在一起。这使得每个模型都处理一个更小、更易于管理的特征空间，从而有效地**降低了维度**。

  

* **灵活性强** (Flexible)：你可以为每种模态选择最适合的机器学习（ML）模型。例如，你可以用一个支持向量机（SVM）来处理临床数据，同时用一个神经网络来处理图像数据。这种灵活性使得模型能更好地适应不同类型的数据。

  

* **处理异构数据** (Addresses heterogeneity)：不同类型的数据（异构数据）有不同的格式和特征，需要不同的预处理方法。晚期整合允许你为每种模态进行**量身定制的预处理**，从而更好地处理这些差异。

  

* **减少过拟合** (Reduces overfitting)：由于每个模型都在较小的特征空间上进行训练，过拟合的风险会大大降低。

  

* **计算复杂度较低** (Lower computational complexity)：训练多个小型模型通常比训练一个包含所有特征的巨大模型要快得多，所需的计算资源也更少。

  

* **模态特定优化** (Modality-specific optimization)：你可以针对每种数据模态的特点来优化模型。例如，你可以调整参数以更好地捕捉基因组数据中的稀疏特征，或者更好地处理蛋白质组学数据中的噪声。

  

---

  

# PAGE 7 Ensemble Methods Evaluated

这是一些在集成学习和多模态数据融合中常用的策略，尤其是用于晚期整合（Late Integration）。

  

---

  

### **1. 投票集成（Voting Ensemble）**

这是最简单的集成方法之一，它结合了多个模型的预测结果。

  

* **硬投票（Hard vote）**：也叫多数投票。每个模型都对类别进行投票，最终结果是获得最多票数的类别。

* **软投票（Soft vote）**：对每个模型的预测概率进行平均，然后选择平均概率最高的类别作为最终结果。软投票通常比硬投票效果更好，因为它考虑了每个模型预测的置信度。

  

---

  

### **2. 元学习器（Meta Learner）**

这种方法使用一个“元模型”来学习如何最好地组合其他模型的预测结果。

  

* **将随机森林作为元分类器**：这是一种常见的实现方式。首先，训练多个基础模型（如决策树、支持向量机等），然后将这些基础模型的预测结果作为新特征，输入给一个“元分类器”（比如随机森林），由这个元分类器来做出最终预测。

  

---

  

### **3. 多模态AdaBoost（Multi-modal AdaBoost）**

  

#### **多模态 AdaBoost**

  

**1. 核心原理：AdaBoost 算法**

  

* **Boosting** 是一种集成技术，通过**按顺序训练一系列弱分类器**来构建一个强大的模型。每个后续分类器都会从前一个分类器的错误中学习。

* **AdaBoost（自适应提升）** 是Boosting的早期算法。它通过在每次迭代中**增加被错误分类样本的权重**，迫使算法专注于这些“难点”样本。最终模型是所有弱分类器的**加权线性组合**。

  

**2. 从 AdaBoost 到多模态 AdaBoost**

  

* **AdaBoost** 最初设计用于二分类任务。

* **多视图 AdaBoost** 将其扩展到多视图或多模态数据，其中每个视图（或模态）都代表一种数据类型。

* **Xiao 和 Guo** 等人的方法是为多语言分析而开发的，它为每个视图训练一个学习器，并使用**硬多数投票或加权组合**来汇总结果。

  

**3. 本文的创新与实现**

  

* 本文基于 Xiao 和 Guo 的方法，实现了一种**多模态版本的 AdaBoost**。

* **训练过程**：在每一轮 Boosting 过程中，会为每种模态**独立训练一个分类器**。

* **结果汇总**：这些独立分类器的结果通过**三种新颖的方法之一**进行汇总，以做出最终决策：

1. **硬投票（Hard Vote）**：多数决定。

2. **软投票（Soft Vote）**：概率加权平均。

3. **元学习器（Meta Learner）**：将独立分类器的结果作为输入，训练一个元模型来做出最终预测。

  

**4. 关键挑战：误分类样本的定义**

  

* 在多模态 AdaBoost 中，定义“误分类”样本变得复杂，因为它需要**考虑所有模态的共同意见**。

* **高置信度分类**的定义是关键。当满足以下条件时，样本才被认为是“正确分类”：

* **硬投票/元学习器**：至少一半的模态对该分类结果表示高置信度的同意。

* **软投票**：最高预测概率至少是次高预测概率的两倍。

* 如果这些条件不满足，该样本则被视为**“误分类”**，其权重将在下一轮 Boosting 中增加。

  

**5. 经验参数**

  

* 根据经验测试，该模型的**最佳 Boosting 迭代次数为 20**。超过这个值，性能不会有显著提升。

  

---

  

### **4. PB-MVBoost**

PB-MVBoost 是一种用于**多视图数据**的集成学习方法，它基于经典的 **AdaBoost** 算法进行了扩展。

  

---

  

#### PB-MVBoost 的核心思想

  

PB-MVBoost 的主要目标是解决集成学习中的一个核心挑战：**如何平衡模型的多样性和准确性？**

  

* **准确性**：每个单独的分类器（或“弱学习器”）都应该在它所处理的视图上表现良好。

* **多样性**：这些分类器之间的预测结果应该有所不同。如果所有分类器都犯同样的错误，集成效果就会很差。

  

PB-MVBoost 通过引入**两组权重**来巧妙地实现这个平衡：

  

1. **分类器权重**：这组权重决定了每个**分类器**对最终结果的贡献大小。表现越好的分类器，权重越高。这和传统的 AdaBoost 类似。

2. **视图权重**：这组权重决定了每个**数据视图**（或模态）对最终结果的贡献大小。如果某个视图提供了更多有用的、独特的信息，它的权重就会更高。

  

---

  

#### 具体工作方式

  

PB-MVBoost 的工作流程可以概括为以下几个步骤：

  

1. **为每个视图训练分类器**：在每一次迭代中，该算法会为每个数据视图（例如基因组、蛋白质组等）训练一个弱分类器。

2. **学习两组权重**：

* **分类器权重**：根据每个分类器在各自视图上的表现（准确率）来更新其权重。

* **视图权重**：根据每个视图对整体集成结果的贡献（或多样性）来更新其权重。

3. **加权投票合并结果**：在每个分类器都完成预测后，PB-MVBoost 使用一个**加权投票**机制来合并所有分类器的结果，其中权重就是前面学习到的分类器权重和视图权重。

4. **最小化误差上限**：该方法的核心优化目标是**最小化多数投票误差的上限**。通过不断迭代和调整两组权重，它试图找到一个最佳的平衡点，使得最终的集成模型既准确又多样化。

  
  

### **5. 混合专家模型（Mixture of Experts）**

这个改进方法，实际上是**对传统混合专家模型在多分类任务中的一个创新应用**，可以更清晰地理解为一种**“一对多”的混合专家模型**。

  

#### **混合专家模型的核心思想**

  

传统的混合专家模型（MoE）通常由两部分组成：

* **专家网络（Expert Networks）：** 多个独立的子模型，每个模型都擅长处理特定类型的数据或子任务。

* **门控网络（Gating Network）：** 一个单独的模型，负责决定哪个专家最适合处理当前的输入数据，并为专家的预测分配权重。

  
  

#### **新颖的“一对多”混合专家模型解释**

  

这个改进方法的核心在于**将一个复杂的多类别分类任务，分解成多个简单的二元分类任务**。

  

* **专家定义：** 每个专家不再是专注于某个数据子集，而是专门负责**区分一个特定的类别**。例如，如果任务是区分A、B、C三个类别，那么就会有三个专家：

* **专家A：** 负责区分“A”和“非A”（即B和C）。

* **专家B：** 负责区分“B”和“非B”（即A和C）。

* **专家C：** 负责区分“C”和“非C”（即A和B）。

* **训练过程：**

* **独立且并行：** 每个专家都是一个独立的二元分类器，它们可以**并行训练**。

* **数据平衡：** 每个专家在训练时，都会独立地平衡自己的数据集。例如，专家A在训练时，会确保它的训练数据中，“A”类别的样本和“非A”类别的样本数量是平衡的。

* **门控函数的决策规则：** 在所有专家都训练完成后，门控函数会根据每个专家的预测结果，来做出最终的决策。

* **唯一预测：** 如果只有一个专家（例如专家B）自信地预测某个样本属于自己的类别（“B”），而其他专家都预测为“非B”（即“REST”），那么这个样本就被判定为“B”。

* **多个预测：** 如果有多个专家（例如专家A和专家B）都预测某个样本属于自己的类别，门控函数会比较它们的**置信度**（即预测概率）。哪个专家的置信度最高，就采纳它的预测。

* **无专家预测：** 如果所有专家都预测“REST”（即都认为样本不属于自己的类别），那么这个样本就会被标记为**“未知”**。这个结果非常有价值，因为它能帮助我们识别那些模型难以分类的样本，从而发现新的子类别或者异常值。

  

---

  

#### **总结**

  

这种改进的混合专家模型，通过将复杂的**多分类问题分解为多个简单的二分类问题**，不仅简化了模型的训练过程，还通过其独特的门控规则，提供了对**不确定样本的识别能力**，这在许多实际应用中（比如疾病亚型分析）是非常有用的。

  

# PAGE 10 11 Data Processing Pipeline

  

---

  

#### **数据过滤步骤 (Filtering Steps)**

  

这些步骤旨在**清理**和**简化**数据，去除那些对分析价值不大的特征。

  

* **删除缺失值超过 50% 的特征**

* **删除零值超过 90% 的特征**：类似于缺失值，如果一个特征绝大多数都是零，那么它的信息量也很低。删除这类特征有助于精简数据集。

* **消除相关性高的特征**：当两个或多个特征高度相关时，它们提供的信息是冗余的。保留其中一个，并删除其他相关特征，可以避免多重共线性问题，并提高模型的效率和可解释性。

* **保留变异性最高的 500 个特征**：如果需要进一步简化数据，可以根据方差（variance）来筛选。方差高的特征通常包含更多的信息，能够更好地在样本间进行区分。这个步骤会保留那些最有区分度的特征。

  

---

  

#### **数据预处理步骤 (Preprocessing Steps)**

  

这些步骤旨在**转换**和**准备**数据，使其适合用于机器学习模型。

  

* **平衡：使用 SMOTE 处理不平衡数据集**：SMOTE（Synthetic Minority Over-sampling Technique）是一种过采样技术，用于解决分类问题中类别不平衡的情况。它会为少数类生成新的合成样本，以平衡数据集，防止模型偏向多数类。

* **插补：使用 MICE 或 k-NN 填充缺失值**：插补（Imputation）是填充缺失值的过程。MICE (Multivariate Imputation by Chained Equations) 和 k-NN (k-Nearest Neighbors) 都是常用的高级插补方法，它们能根据数据集中已有的信息来预测并填充缺失值，而不是简单地删除数据。

* **归一化：RNA/DNA 数据使用 CPM + 对数转换**：对于基因组学或转录组学数据，这是一种常见的预处理方法。

* **CPM (Counts Per Million)**：将原始的基因计数数据转换为每百万读数的计数，以校正文库大小差异。

* **对数转换**：对数据进行对数变换，可以压缩数据的范围，使其分布更接近正态分布，这对于许多机器学习算法都是有利的。

* **特征选择：使用 Boruta 算法和 GBM**：特征选择旨在从数据中找出最相关的特征。

* **Boruta 算法**：一种基于随机森林的特征选择算法，它能有效识别出所有与目标变量相关的特征，而不仅仅是那些最强的特征。

* **GBM (Gradient Boosting Machine)**：梯度提升机，这是一种强大的机器学习模型，常用于 Boruta 算法中作为基础分类器。

  
  

#### 为什么需要 CPM？（视时间定讲不讲）

  

想象一下你做了两个 RNA-seq 实验，来比较两种细胞状态下的基因表达量：

  

* **实验 A** 产生了 1000 万个测序读数。

* **实验 B** 产生了 2000 万个测序读数。

  

现在，你发现基因 X 在实验 A 中有 100 个读数，在实验 B 中有 150 个读数。如果你只看原始读数，你可能会错误地认为基因 X 在实验 B 中的表达量更高。

  

但事实上，实验 B 产生了更多的总读数（文库大小更大），所以它有更高的读数是意料之中的。你不能直接比较这两个原始读数。

  

#### CPM 如何解决这个问题？

  

CPM 的作用就是**校正文库大小差异**。它将每个基因的读数，转换为在每百万总读数中所占的比例。

  

**计算公式：**

$$\text{CPM} = \frac{\text{特定基因的原始读数}}{\text{总读数}} \times 1,000,000$$

  

**应用到上面的例子：**

  

* **实验 A 中基因 X 的 CPM：**

$$\frac{100}{10,000,000} \times 1,000,000 = 10 \text{ CPM}$$

* **实验 B 中基因 X 的 CPM：**

$$\frac{150}{20,000,000} \times 1,000,000 = 7.5 \text{ CPM}$$

  

通过 CPM 标准化后，我们发现基因 X 在实验 A 中的相对表达量（10 CPM）实际上高于实验 B（7.5 CPM）。

  

#### 深层含义总结

  

CPM 的深层含义在于：它将原始的、受实验条件影响的**绝对计数**，转换为可以相互比较的、反映**相对丰度**的数值。这使得研究人员能够：

  

* **跨样本比较**：准确地比较不同样本（即使文库大小不同）中同一个基因的表达水平。

* **跨基因比较**：在同一个样本中，比较不同基因的表达水平，尽管由于基因长度等因素，这种比较需要更复杂的标准化方法（如 FPKM 或 TPM）。

  

好的，这是一个关于 MICE 和 KNN 两种缺失值插补方法更详细的解释。

  

---

  

#### **缺失值插补方法详解：MICE 与 k-NN**

  

在数据分析中，缺失值是一个普遍存在的问题。我们不能直接将含有缺失值的数据输入到大多数机器学习模型中。因此，我们需要使用插补技术来填充这些缺失值。

  

这两种方法代表了两种不同的插补思想：**多重插补**（Multiple Imputation）和**单一插补**（Single Imputation）。

  

##### **1. 链式方程多重插补法（MICE）**

  

MICE 是一种**多重插补**方法，它的核心思想是：**缺失值不是一个确定的值，而是一个具有不确定性的范围**。MICE 会生成多个完整的、略有不同的数据集，来捕获这种不确定性。

  

**MICE 的工作流程**

  

MICE 的过程就像一个循环的“猜谜”游戏：

  

1. **初始化：** 首先，用一个简单的插补方法（比如均值）来填充所有缺失值，得到一个初步完整的“热身”数据集。

2. **迭代插补：**

* MICE 会针对每一个有缺失值的变量，**逐一**进行插补。

* 例如，要插补变量 $X_1$ 的缺失值，它会把 $X_1$ 作为**因变量**，把数据集中其他所有变量（$X_2, X_3, ...$）作为**自变量**，建立一个回归模型。

* 然后，利用这个模型，预测 $X_1$ 的缺失值，并用**预测值 + 随机误差**来填充它。

* 这个过程会在所有有缺失值的变量上反复进行，形成一个“链式”循环。

3. **生成多个数据集：** 重复这个迭代过程多次（例如，5 到 10 次），每次都会产生一个略有不同的完整数据集。

4. **最终分析：** 对这 N 个完整数据集分别进行建模和分析，得到 N 个结果。最后，使用专门的规则（如 Rubin’s Rules）将这 N 个结果进行**合并**，得到一个最终的、更稳健的结论。

  

**优点**

  

* **更稳健的统计推断：** MICE 能够反映插补值的不确定性，这使得用插补后的数据进行统计分析（如置信区间、p 值）时，结果更加可靠。

* **高度灵活：** 它可以针对不同类型的变量（连续型、二元型、类别型）使用不同的预测模型。

  

**缺点**

  

* **计算成本高：** 尤其是当数据集很大或缺失变量很多时，MICE 需要多次迭代和建模，计算时间会显著增加。

  

---

  

##### **2. K近邻单一插补法（k-NN）**

  

k-NN 是一种**单一插补**方法，它的核心思想是：**“物以类聚，人以群分”。** 它假设缺失值可以用与其最相似的样本的值来代替。

  

**k-NN 的工作流程**

  

k-NN 的过程相对直观：

  

1. **定义距离：** 首先，定义一个衡量样本之间相似性的**距离度量**（如欧氏距离）。

2. **寻找近邻：** 对于一个有缺失值的样本，k-NN 会在数据集中找到与它最相似的 $k$ 个样本。

3. **插补填充：**

* 如果缺失的是**连续型变量**，它会用这 $k$ 个近邻的对应值的**平均值或中位数**来填充。

* 如果缺失的是**类别型变量**，它会用这 $k$ 个近邻中出现次数最多的类别来填充（**众数**）。

  

**优点**

  

* **考虑数据结构：** k-NN 不像均值插补那样简单粗暴，它利用了样本之间的相似性，因此填充值通常更加合理。

* **计算效率高：** 相较于 MICE，k-NN 的计算速度更快，尤其适用于处理大规模数据。

  

**缺点**

  

* **忽视不确定性：** k-NN 只提供一个单一的填充值，忽略了插补的随机误差。这可能导致后续分析中的标准误差被低估。

* **对维度和异常值敏感：** 当数据维度很高时，计算距离会变得困难。此外，异常值也可能影响近邻的选择，从而影响插补的准确性。

  

---

  

#### **总结与应用场景**

  

* **MICE** 在**需要进行稳健统计推断**或**数据集规模适中**时是更好的选择。它能提供更可靠的分析结果，但计算量大。

* **k-NN** 在**数据集规模庞大**或**对计算时间有严格要求**时是更实用的替代方案。它提供了一个快速、相对准确的插补，但牺牲了对不确定性的捕捉。

  

在你的描述中，根据计算时间来动态选择 MICE 或 k-NN 是一种非常明智且务实的策略。

  

这段对 Boruta 算法的描述非常详细和准确，涵盖了其核心思想、工作原理、与传统方法的区别以及优势。以下是结构化和精炼后的版本，旨在使其更易于理解。

  

---

  

#### **基于 Boruta 的特征选择**

  

Boruta 是一种**全相关（all-relevant）**的特征选择算法，它旨在识别出**所有**与目标变量有统计学关联的特征，而不仅仅是那些最能提高模型预测精度的特征。

  

##### **工作原理**

  

Boruta 是一种**模型无关（model-agnostic）**的封装算法，它可以与任何能够提供特征重要性评估的底层机器学习模型（如随机森林、梯度提升机等）配合使用。它的核心工作流程如下：

  

1. **创建“影子”特征**：Boruta 首先为每个原始特征创建一组**随机打乱（shuffled）**的副本，这些副本被称为“影子特征”。

2. **构建混合数据集**：它将原始特征和所有影子特征组合成一个更大的数据集。

3. **迭代训练**：

* Boruta 在这个混合数据集上**反复训练**底层学习器（例如随机森林或你提到的梯度提升机）。

* 在每次训练后，它都会计算每个特征（包括原始特征和影子特征）的重要性得分。

4. **确定重要性阈值**：Boruta 会找到**所有影子特征中的最高重要性得分**。这个得分就成为了一个动态的、基于数据的**阈值**。

5. **筛选特征**：

* 任何原始特征的重要性得分**高于**这个阈值，就被认为是**“重要”**的。

* 任何原始特征的重要性得分**低于**这个阈值，就被认为是**“不重要”**的，并在下一轮迭代中被移除。

6. **最终结果**：经过多次迭代后，所有未被移除的原始特征都被 Boruta 算法认定为与目标变量相关的特征。

  

##### **与传统方法的对比**

  

Boruta 的“全相关”方法与传统的“最小最优”方法有所不同：

  

* **全相关（Boruta）**：其目标是**知识发现**。它会找出所有对预测有贡献的特征，即使某些特征的影响较弱或与其他特征相关。这在生物医学研究等领域非常有用，因为它可以帮助研究人员全面了解哪些生物标志物与疾病相关。

* **最小最优（传统方法）**：其目标是**最大化预测准确度**。这类方法通常只选择一个最小的、最强大的特征子集。这在预测是主要目的、对可解释性要求不高的场景中很有用。

  

##### **总结**

  

使用梯度提升机（GBM）作为底层学习器来运行 Boruta 算法是一种强大的组合，它能利用 GBM 在处理复杂数据时的优势，同时利用 Boruta 算法的全面性，确保识别出所有与预测任务相关的特征，为后续的知识发现和模型解释提供坚实基础。

  
  

# PAGE 12 DATASETS

这张图片展示了一个表格，总结了多个研究中使用的数据集，这些数据集涵盖了三种主要疾病：肝细胞癌（HCC）、炎症性肠病（IBD）和乳腺癌（Breast cancer）。

  

---

  

### 表格主要内容

  

表格的每一行代表一个数据集，详细介绍了该数据集的以下特征：

  

* **数据库名称 (DB name)**：数据集的简称，例如 HCC-Genous、IBD-1、Breast-1 等。

* **参考文献 (Reference)**：提供原始研究的引用，包括作者、期刊和 DOI。

* **病人类别 (Patient categories)**：列出研究中包含的病人群体，并附有缩写。例如，HCC-Genous 数据集包括健康对照组（CON）、脂肪肝（MAFLD-cirrhosis）等。

* **样本数量 (No. samples)**：每个病人类别中的样本总数。

* **组学模态 (Omics modalities)**：研究中使用的不同数据类型，例如临床数据（CLIN）、细胞因子（CYT）、病理结果（PATH）、宏基因组学（Metagenomics）、RNA 测序（RNA）等。

* **特征数量 (No. features)**：每种组学模态中包含的特征总数。

  

---

  

### 关键发现

  

从表格中可以看出，这些研究都采用了**多组学（Multi-omics）**方法来分析疾病。这意味着它们不仅仅依赖单一类型的数据，而是整合了多种数据源（如临床、基因、蛋白质、微生物等）来获得更全面的洞察。

  

例如：

* **HCC-Genous** 数据集整合了临床、细胞因子、病理、代谢组学和脂蛋白等多种数据。

* **IBD-1** 数据集使用了宏基因组学、元转录组学、代谢组学和病毒组学等数据。

* **Breast-2** 数据集结合了临床、mRNA 和蛋白质组学数据。

  

表格最底部的脚注解释了最后一列**特征数量**的含义，它指出了在模型构建中使用的特征总数和相关特征的数量。这强调了特征选择在这些研究中的重要性。

  

总而言之，这张表格提供了一个全面的概览，展示了如何利用多样化的多组学数据来研究和分析复杂的疾病。

  
  

# PAGE 15 PERFORMANCE RESULTS

### **主要发现**

  

* **最佳表现者**：PB-MVBoost 和使用**软投票**的 AdaBoost 表现最佳。

* **峰值性能**：在肝细胞癌（HCC）数据集上，模型的最高性能达到了 **AUC 0.85**。AUC（Area Under the Curve，曲线下面积）是衡量分类模型性能的重要指标，AUC 0.85 表示模型具有非常好的区分能力。

* **多模态优于单模态**：在大多数情况下，整合了多种数据类型（多模态）的方法表现优于只使用单一数据类型（单模态）的方法。这印证了多组学数据提供互补信息的观点。

* **软投票优于硬投票**：在投票集成中，对预测概率进行平均的**软投票**方法，其表现始终优于简单的多数决定的**硬投票**。这是因为软投票考虑了每个模型的置信度。

  

---

  

### **核心洞见**

  

研究者认为，Boosting 方法之所以表现出色，主要归功于以下几点：

  

* **减少过拟合**：Boosting 通过逐步学习并纠正错误，有效防止了模型在训练数据上过度学习，从而提高了泛化能力。

* **模态加权**：这类方法能够为不同的数据模态分配权重，让模型自动学习哪些模态对最终预测更重要。

* **适合高维、小样本数据**：Boosting 方法特别适合处理那些特征数量远大于样本数量的数据集，这正是许多多组学研究的特点。


# PAGE 17 INDIVIDUAL VS MULTI-MODEL
这张图展示了一个表格，比较了在不同数据集上，最佳表现的**多模态方法（MM）**和最佳表现的**单一模态方法（Ind）**的性能。

---

### **表格主要内容**

表格的每一行代表一个在特定数据集上的性能比较。列出了以下指标：

- **数据集 (Dataset)**：具体的数据集，如 HCC-Genous、IBD1、Breast1 等。
    
- **模态/方法 (Modality/Method)**：
    
    - **Ind**：表示在该数据集上表现最好的**单一模态**，并给出了具体模态的缩写（如 CYT, MTB, CLIN, PROT）。
        
    - **MM**：表示在该数据集上表现最好的**多模态方法**，并给出了具体方法的名称（如 PB-MVBoost, Concatenation, AdaBoost-Soft, Meta learner）。
        
- **AUROC**：ROC 曲线下面积，一个衡量分类模型区分能力的重要指标。
    
- **F1**：F1 分数，是精确率（Precision）和召回率（Recall）的调和平均值，用于综合评估模型的性能。括号中的数值是标准差。
    
- **Acc**：准确率（Accuracy），模型正确预测的样本比例。
    
- **Sens**：敏感度（Sensitivity），即召回率，衡量模型识别出所有正例的能力。
    
- **Spec**：特异度（Specificity），衡量模型识别出所有负例的能力。
    

---

### **关键发现**

从表格中可以得出以下几个核心结论：

1. **多模态方法普遍优于单一模态**：在大多数数据集上（如 HCC-Genous、HCC-Species、IBD1、IBD2 和 Breast1），多模态方法的 AUROC、F1、Acc 和 Sens 等指标都高于单一模态方法。这有力地支持了**多组学数据整合能提升模型性能**的论点。
    
2. **方法性能因数据集而异**：在不同的数据集上，表现最好的多模态方法也不同。例如，在 HCC 数据集上是 **PB-MVBoost**，在 IBD2 上是 **AdaBoost-Soft**，在 Breast1 上则是 **Meta learner**。这表明没有一种“万能”的整合方法，选择最适合的策略取决于数据的具体特性。
    
3. **多模态并非万能**：在 **Breast2** 数据集上，多模态方法 **Concatenation** 的 AUROC 与单一模态 **PROT**（蛋白质组学）相同，且在 F1 和 Sens 等指标上甚至表现稍逊。这说明在某些情况下，单一、高质量的模态可能已经包含了足够的信息，或者简单拼接的多模态方法并不能有效整合信息。
    

总之，这张图表通过具体的数据指标，直观地展示了多模态数据整合的有效性，同时也强调了选择合适的整合方法和数据预处理的重要性。

# PAGE 18 FEATURE SELECTION
### **方法表现**

- **拼接（Concatenation）**：这种方法在特征选择上**最不稳定**。由于它直接将所有特征组合在一起，导致高维性问题，特征选择的结果容易受到数据中的微小变化影响，从而使得选出的“重要”特征在不同数据子集上差异很大。
    
- **PB-MVBoost**：这种方法在所有测试中展现出**最高的稳定性和准确性**。这表明它能够持续地识别出真正重要的特征，并且其预测性能也很可靠。
    
- **AdaBoost（软投票）**：这种方法在**稳定性**和**特征签名长度**之间取得了很好的平衡。这意味着它既能稳定地选出特征，同时又不会产生过多的冗余特征。
    
- **整合方法克服了高维不稳定性**：总体而言，多模态整合方法（尤其是像 PB-MVBoost 和 AdaBoost 这样的高级方法）能够有效解决由高维数据带来的不稳定性问题，使特征选择结果更加可靠。
    

---

### **临床特征签名特性**

一段理想的“临床特征签名”（Clinical Signature），也就是用于诊断、预测或预后的一组生物标志物，应该具备以下几个**理想属性**：

- **特征签名长度较短**（Shorter signature length）：签名中包含的特征（如基因、蛋白质等）越少越好。这不仅可以简化模型，还可以降低实验成本。
    
- **所需模态较少**（Fewer modalities required）：如果能用更少的数据类型（例如只用基因组和临床数据，而不是所有六种组学数据）来达到同样好的预测效果，那么模型会更实用、更容易在临床上推广。
    
- **高稳定性和高准确性**（High stability and accuracy）：一个可靠的特征签名应该在不同病人群体中都能保持一致的预测能力，并且其结果应该高度准确。
    
- **临床可解释性**（Clinical interpretability）：特征签名中的每个特征都应该有明确的生物学意义或临床关联，这样医生和研究人员才能理解模型的决策依据，并将其应用于实践。


# PAGE 19 OPTIMAL MODALITY SUBSET
这张图展示了一个表格，名为“增量模型在确定每个数据集中最佳模态子集方面的性能”。它通过**逐步移除模态**的方式，来测试每个模态对模型性能的影响，并确定哪个子集是最佳的。

---
### 表格主要内容

表格的每一行都代表了一个数据集，并分为四列：

- **数据集 (Dataset)**：研究分析的具体数据集，如 HCC、IBD1、IBD2、Breast1 和 Breast2。
    
- **最佳子集 (Best subset)**：在所有模态组合中，模型表现最好的模态子集。
    
- **移除的模态 (Modality removed)**：列出了从完整模态集中移除的模态，并按照移除的顺序排列。
    
- **移除后的 F1 得分 (F1 score after removal)**：每次移除一个模态后，模型所达到的 F1 得分。
    

### 关键洞察

这张表格的核心目的是**评估不同模态的贡献度**。通过观察 F1 得分的变化，我们可以确定哪些模态是预测的关键，以及哪些模态可能是冗余的。

例如：

- **HCC 数据集**：最佳子集是 **CLIN, CYT, METAB**（临床、细胞因子、代谢组学）。当从完整的数据集中移除其他模态（如微生物组学、病理学）时，F1 得分从 0.68 逐步上升到 0.73。这表明被移除的模态可能包含了噪声或冗余信息，移除后反而提升了模型性能。
    
- **IBD1 数据集**：最佳子集是 **MTB, MTG**（元转录组学、宏基因组学）。移除病毒组学（VIR）和元转录组学（MTX）后，F1 得分略有下降，说明这些模态可能具有一定的预测价值。
    
- **Breast1 数据集**：最佳子集是 **CLIN**（临床数据）这表明对于这个数据集，仅使用临床数据就能获得最佳性能。当移除 DNA、RNA 和 PATH（病理学）等模态后，F1 得分从 0.60 显著下降到 0.22 和 0.25，这说明这些模态**对模型性能至关重要**。
    
- **Breast2 数据集**：最佳子集是 **PROT**（蛋白质组学）。移除临床和 mRNA 模态后，F1 得分反而上升了，这暗示这两种模态可能不是这个特定数据集中最有用的预测因子。
    

总而言之，这张表格通过一种系统性的“移除测试”方法，为我们提供了哪些数据模态对于预测最关键的洞察，并且指出了多模态数据整合并非总是将所有数据都囊括在内，有时去除冗余或无关的模态反而能提升模型性能。

# PAGE 20 21
**增量模型（Incremental Model）**核心思想是**通过系统性地移除模态，来找到一个最优的、最精简的模态子集**。
### **增量模型：从临床到算法**(视情况讲不讲)

#### **1. 临床动机**

从临床角度来看，一个理想的诊断或预测模型应该：

- **准确**：能够做出可靠的预测。
    
- **精简**：所需的检测项目越少越好。
    
- **经济**：能降低医疗成本。
    
- **微创**：对患者的负担和创伤最小。
    

增量模型正是为了实现这些目标而设计的。它不是盲目地使用所有可用数据，而是旨在**找到一个最小化的诊断模块子集**，这个子集既能保持高预测性能，又能最大化临床效益。

---

#### **2. 算法设计与工作流程**

增量模型的核心在于其独特的**“从全到简”**的工作流程：

1. **初始状态**：模型从**所有可用的模态**（例如基因组、蛋白质组、临床数据等）开始。
    
2. **迭代移除**：在每一轮迭代中，模型会系统性地进行以下操作：
    
    - **移除一种模态**：从当前的模态集中，**暂时移除**一种模态。
        
    - **重新训练和评估**：在剩余的模态子集上**重新训练模型**，并使用 F1 分数等指标来评估其性能。
        
    - **确定移除顺序**：通过比较所有可能的移除方案，找到那个**移除后性能提升最大或下降最小**的模态。这个被移除的模态就被确定为**下一轮要正式移除的模态**。
        
3. **精简子集**：这个过程会不断重复，直到找到一个**无法再移除任何模态而又不显著影响性能**的“最优子集”。
    

#### **3. 模型核心**

- **集成策略**：为了整合不同模态的预测结果，该模型采用了**软投票集成**方法。软投票通过平均各模态的预测概率，能够更好地利用每个模态的置信度信息。
    
- **评估指标**：使用 **F1 分数**作为主要比较指标，因为它能综合考虑模型的精确率和召回率，尤其适用于处理类别不平衡的数据集。
    
- **容忍误差**：在比较性能时，模型允许存在**少量误差**。这意味着即使移除某个模态后性能略有下降，只要在可接受的范围内，模型仍可能将其移除，以换取更精简的诊断方案。
    

---

### **补充总结**

增量模型代表了一种从**实践需求驱动算法设计**的思路。它不仅关注模型的预测准确性，更关注其在现实世界中的**可行性和价值**。通过这种方法，研究者可以系统地量化每个诊断模块（或模态）的贡献，从而为开发更高效、更经济的临床工具提供坚实的数据支持。
## **主要发现**

- **增量模型**：这种模型能够帮助我们找到**最优的模态子集**。其核心思想是通过逐步添加或移除模态，来观察模型性能的变化，从而确定哪些模态是真正有价值的。
    
- **更少的模态，同样的性能**：研究发现，在某些数据集中，使用更少的模态，模型仍然可以达到与使用全部模态时**相同甚至更好的性能**。
    
- **临床益处**：
    
    - **减少所需的检测**：如果只需要更少的模态就能获得准确的诊断或预测结果，那么在临床实践中，医生只需要对病人进行更少的检测。
        
    - **降低成本和复杂性**：减少检测不仅能节省医疗费用，还能简化整个临床流程，使诊断或预后分析更具可行性。
        

### **举例：HCC 数据集**

- **完整数据集**：包含 **7 种模态**。
    
- **最优子集**：只需要 **3 种模态**。
    
- **性能保持**：通过使用这个最优子集，研究在**减少了 57% 的检测数量**（从 7 减少到 3）的情况下，仍然保持了模型的性能。
    

这表明，并非所有数据都有助于提高模型性能，有时数据中的冗余或噪声反而会降低效果。找到最佳子集，既能简化模型，又能带来显著的临床和经济效益。


# PAGE 23 KEY FINDINGS
---

- **Boosting 方法更优越**：像 **PB-MVBoost** 和 **AdaBoost** 这样的 **Boosting** 算法表现出色。这是因为它们通过逐步学习和纠正错误，能够有效处理复杂的高维数据，并找到最优的预测模型。
    
- **软投票更好**：在集成方法中，**软投票（Soft voting）**优于硬投票（Hard voting）。软投票通过平均各个模型的预测概率，能更精细地权衡每个模型的置信度，从而做出更准确的决策。
    
- **多模态的益处**：多模态方法之所以有效，是因为它们能**利用来自不同数据源的互补信息**。这使得模型对疾病机制的理解更全面，预测也更准确。
    
- **稳定性很重要**：特征选择的**一致性（stability）**非常关键。如果特征选择的结果在不同数据子集上不稳定，那么模型的可靠性就会受到质疑。研究发现，好的多模态整合方法能有效提高特征选择的稳定性。
    
- **模态优化**：并非所有的数据模态都同样有价值。在构建模型时，需要**优化模态的使用**，找出那些对预测最有贡献的子集，这有助于减少成本和复杂度，同时保持高性能。

# PAGE 24 BOOSTING
这段文本对比了 Boosting 方法与其他集成方法在处理多模态数据时的优势。

---

### **Boosting 方法的优势**

- **减少过拟合（Reduces overfitting）**
    
    - **Boosting** 算法通过按**顺序训练一系列弱学习器（sequential weak learners）**，逐步纠正前一个模型的错误。
        
    - 它**专注于那些难以分类的样本（focus on difficult samples）**，不断提高对这些样本的预测准确性。这种方法能有效防止模型在训练数据上过度学习，从而提高在未见过数据上的泛化能力。
        
- **模态加权（Modality weighting）**
    
    - Boosting 算法能够为不同的数据模态分配**权重**，从而**优先考虑那些具有更强预测能力的模态（prioritizes predictive modalities）**。
        
    - 这些**重要性分数（importance scores）**是算法在训练过程中自动学习的，这使得模型能够智能地利用每种模态的独特信息。
        
- **适用于高维数据（High-dimensional suitability）**
    
    - Boosting 方法特别为处理**挑战性数据集**而设计。
        
    - 它们非常适合处理**样本数量少、特征数量多（small sample, large feature spaces）**的数据，这正是许多多组学研究所面临的典型情况。
        

---

### **对比其他方法**

- **其他方法**：一些简单的整合方法（例如直接的硬投票或拼接），会给**所有模态赋予相同的权重**。
    
- **潜在问题**：这种做法可能会**稀释（diluting）**那些真正有价值模态的预测能力。因为那些包含较多噪声或信息量较低的模态，也会对最终结果产生同等影响。
    

简而言之，Boosting 方法的优势在于它能够**智能地学习和分配权重**，从而更有效地利用多模态数据的潜在价值，而不会被无关或冗余的信息所干扰。


# PAGE 25 
### **多模态整合的益处**

- **个体化医疗**（Personalized medicine）：通过多模态数据分析，可以更精确地**对患者进行分层**（patient stratification）。这意味着可以根据每个人的独特生物学特征，为他们量身定制最有效的治疗方案，实现真正的个体化医疗。
    
- **生物标志物发现**（Biomarker discovery）：该方法能够识别出**稳定且可靠的特征签名**（stable feature signatures）。这些签名可以作为诊断、预测预后或监测治疗反应的生物标志物，其稳定性对于临床应用至关重要。
    
- **成本降低**（Cost reduction）：通过确定**最佳模态子集**（optimal modality subsets），研究者可以找到以最少检测项目达到最佳诊断效果的方案，从而显著**降低医疗成本**。
    
- **诊断效率**（Diagnostic efficiency）：由于所需的检测更少，整个诊断流程变得**更简单、更快捷**，从而提高了诊断的效率。
    
- **机制洞察**（Mechanistic insights）：通过分析多模态数据中各个特征的重要性，可以深入理解疾病的**潜在生物学机制**，这对于药物开发和治疗策略的制定至关重要。
    

---

### **未来应用方向**

- **药物反应预测**（Drug response prediction）：通过分析患者的多模态数据，预测他们对特定药物的反应，从而为治疗选择提供依据。
    
- **疾病进展监测**（Disease progression monitoring）：利用多模态数据追踪疾病的动态变化，从而更好地监测疾病的进展。
    
- **治疗选择指导**（Treatment selection guidance）：根据患者的多维数据，为医生提供最佳治疗方案的推荐，辅助临床决策。


# PAGE 27
一个关于多模态数据整合的**推荐工作流程**。它将整个过程分解为几个关键步骤，从最初的探索性分析到最终的模型验证。

---

### 推荐工作流程

1. **首先检查单一模态**（Examine individual modalities first）
    
    - **目的**：在进行复杂的整合之前，首先要对每一种单独的模态（如基因组学、临床数据等）进行分析。
        
    - **操作**：识别出那些最具预测能力的模态。这有助于我们了解哪些数据类型本身就提供了强大的信息，哪些可能包含更多噪音。
        
2. **应用增量方法**（Apply incremental method）
    
    - **目的**：确定能够提供最佳预测性能的最小模态子集。
        
    - **操作**：通过逐步添加或移除模态，来找到一个最优的组合。这有助于简化模型，减少成本和复杂性。
        
3. **使用 Boosting 方法**（Use boosting methods）
    
    - **目的**：利用强大的集成学习方法来构建最终模型。
        
    - **操作**：推荐使用 **PB-MVBoost** 或**带软投票的 AdaBoost**。这些方法在处理高维、小样本数据时表现出色，并能智能地分配模态权重。
        
4. **考虑稳定性**（Consider stability）
    
    - **目的**：确保模型的可靠性和可解释性。
        
    - **操作**：在选择特征时，要平衡模型的**准确性**和特征选择结果的**一致性**。一个稳定的模型在不同的数据子集上应该能选出相似的核心特征。
        
5. **在多个数据集上进行验证**（Validate across datasets）
    
    - **目的**：确保模型的泛化能力。
        
    - **操作**：将模型在不同的数据集上进行验证，以确保其不仅仅在特定的训练数据上表现良好，而是具有普遍适用性。
        

这个流程是一个从**探索性分析**到**精细化建模**，再到**严谨验证**的完整过程，旨在构建一个既准确又具有临床实用性的多模态数据整合模型。

# PAGE 28 FUTURE
### **未来研究方向**

- **深度学习整合（Deep learning integration）**：将**神经网络集成方法**应用于多模态数据整合。深度学习在处理复杂、高维数据方面有天然优势，可以更好地捕捉不同模态数据之间的非线性关系。
    
- **纵向数据（Longitudinal data）**：对**时间序列多模态数据**进行分析。纵向数据是指在不同时间点收集的样本数据（例如，患者在治疗前、中、后的数据）。分析这类数据可以更好地理解疾病的动态变化和治疗效果。
    
- **联邦学习（Federated learning）**：开发**多中心协作模型**。联邦学习允许多家医院在不共享原始数据的情况下，共同训练一个强大的模型。这能有效解决数据隐私问题，同时利用更大规模的数据集来提高模型性能和泛化能力。
    
- **可解释性增强（Interpretability enhancement）**：为临床决策支持开发**可解释的人工智能**（Explainable AI）。在医疗领域，仅仅有准确的预测是不够的，医生还需要理解模型做出决策的依据。提高模型的可解释性对于其在临床上的应用至关重要。
    
- **真实世界验证（Real-world validation）**：进行**前瞻性临床研究**。所有在实验室中开发的模型最终都需要在真实世界中进行验证。通过前瞻性临床研究，可以评估模型在实际医疗环境中的性能、稳定性和临床价值。